---
title: "Pangenómica del dominio Archaea"
author: "Hilda & Abelardo"
date: "2023-02-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

#### Primero leemos la tabla completa de arqueas disponibles en "Genomes" NCBI


```{r leer_tabla}
archaea_all <- read_csv("/home/arquea/Pangenómica/Arqueas_2023/archaea_all_taxized.csv")
archaea_all
```


### 1)Eliminar genomas que no tengan archivo .faa

```{r filter_by_pcount}
archaea_pcount <- archaea_all[!is.na(archaea_all$`Annotation Count Gene Protein-coding`),]
archaea_pcount <- archaea_pcount[!is.na(archaea_pcount$species),]
archaea_pcount$pcount <- archaea_pcount$`Annotation Count Gene Protein-coding`
archaea_pcount
```

### 2) Añadir taxonomía a todos los genomas 
Para seleccionar los genomas que usaremos en el estudio, primero
añadimos la taxonomía de todos los organismos de la lista 
desde el nivel más inclusivo (phylum) hasta el menos inclusivo (especie)

``` {r Add_taxonomy, include=TRUE}
get_expanded_classification <- function(in_DF,colname){
  input_classification <- in_DF[,grep(colname,colnames(in_DF))] %>% dplyr::pull(colname) %>% unique() # generates a non redundant input vector for get_ids
  results <- taxize::classification(input_classification, db = "ncbi", rows = 1, messages = FALSE) # save results of non interactive get_ids
  results_unlisted <- results %>% unlist() # unlist results
  all_ranks <- results_unlisted[grep("rank", names(results_unlisted))] %>% unname() %>% unique() # complete repertoire of taxonomic ranks
  
  out_DF <- matrix(nrow = length(results), ncol = length(all_ranks) + 1) %>% as.data.frame(.) # output data frame many rows as organisms, many columns as ranks
  colnames(out_DF) <- c(colname, paste(colname, c(all_ranks), sep = "_")) # naming of taxonomic rank columns
  
  # for loop to match taxonomic classifications
  index = 0 # iterative variable
  for (e in input_classification) {
    index = index + 1 # update iterative variable
    clasif <- results[[e]] # retrieve classification found for organism e
    out_DF[index ,which(colnames(out_DF) == colname)] <- e # write query name in first column
    if(any(is.na(clasif))){next}
    # for each species, iterate over each global taxonomic range
    for (r in all_ranks) {
      r_classif <- clasif$name[grep(r,clasif$rank)] # given lineage for rank r
      r_outDF_index <- grep(r, colnames(out_DF)) # define column index of rank r
      if(length(r_classif)==0){out_DF[index,r_outDF_index] <- ""}else{out_DF[index,r_outDF_index] <- r_classif[1]} # conditionally fill output df if a given rank was assigned for a given query
    }
  }
  return(out_DF)
}
```


### 3) Reducción de redundancia

###### Criterio 1: No queremos más de un genoma por especie####################

#### Para escoger a nuestros 3 representantes, ordenaremos la tabla conforme a las siguientes prioridades jerárquicas:

 - 1.- Nivel de ensamblaje (complete genome > chromosome > scaffold)
 - 2.- Conteo de proteínas
 - 3.- Fecha
 
 
```{r sort_priorities}
archaea_pcount$`Assembly Level` <- as.factor(archaea_pcount$`Assembly Level`)
archaea_pcount$`Assembly Level` <- factor(archaea_pcount$`Assembly Level`,  levels = c("Complete Genome", "Chromosome", "Scaffold"))
archaea_pcount$Assembly_score <- unclass(archaea_pcount$`Assembly Level`)


archaea_pcount_sorted <- archaea_pcount %>% arrange(species,
                           Assembly_score,
                           desc(pcount),
                           desc(`Assembly Submission Date`))

archaea_pcount_sorted$selection_priority <- 1

for (i in 2:nrow(archaea_pcount_sorted)) {
  if(archaea_pcount_sorted$species[i] != archaea_pcount_sorted$species[i-1]){
    archaea_pcount_sorted$selection_priority[i] <- 1
  } else {
    archaea_pcount_sorted$selection_priority[i] <- archaea_pcount_sorted$selection_priority[i-1] + 1
  }
}


```

#### Ahora con la columna "selection priority" podemos escoger un valor máximo de genomas por especie. En nuestro caso será de uno.


```{r max_count}
max_count <- 1
```


```{r reduced_by_species}
reduced_by_species <- archaea_pcount_sorted[(!archaea_pcount_sorted$selection_priority > max_count),]
reduced_by_species
```


##### Criterio 2: Solo aquellos clasificados hasta phylum################

#### Eliminaremos aquellas para las cuales no se tiene informaciónalguna sobre el phylum al que pertenecen.

```{r reduced_by_phylum}
reduced_by_phylum <- reduced_by_species[which(!is.na(reduced_by_species$phylum)),]
reduced_by_phylum
```

#### Criterio 3: Reducción porcentual por representatividad##################

#### En este punto, notamos que no valdría la pena realizar una reducción homogenea, debido a que los phyla están representados de forma muy heterogenea. Para ello, agrupamos en 3 categorías:

 - Con menos de 100 genomas              No. genomas < 100
 - Más de 100, menos de 500        500 > No. genomas > 100
 - Más de 500                            No. genomas > 500
 
#### Con ello realizaremos una reducción porcentual, siendo más astringentes en aquellos que lo permiten, es decir, los que tienen más genomas. Primero necesitamos nuestras tres tablas.

```{r grouped_by_representatives}

Count_by_phylum <- reduced_by_phylum %>% group_by(phylum) %>% summarise(r_count = n())
Under100 <- Count_by_phylum %>% filter(r_count < 100) %>% select(phylum)
Over100 <- Count_by_phylum %>% filter(r_count > 100) %>% filter(r_count < 500) %>% select(phylum)
Over500 <- Count_by_phylum %>% filter(r_count > 500) %>% select(phylum)

Under100_tb <- reduced_by_phylum %>% filter(phylum %in% Under100$phylum)
Over100_tb <- reduced_by_phylum %>% filter(phylum %in% Over100$phylum)
Over500_tb <- reduced_by_phylum %>% filter(phylum %in% Over500$phylum)
```

#### Ahora nos enfocamos en reducciones con criterios distintos dependiendo de la situación particular por tabla.

## Under100

```{r Under100_reduction}

Under100_tb_decisions <- Under100_tb %>% group_by(phylum) %>% summarise(phylum_count = n(), remaining = ceiling(0.8 * n()))
Under100_tb_decisions

Under100_tb$lottery <- sample(1:nrow(Under100_tb))

Under100_tb_sorted <- Under100_tb %>% arrange(phylum,
                                              lottery)

Under100_tb_sorted$selection_priority_2 <- 1

for (i in 2:nrow(Under100_tb_sorted)) {
  if(Under100_tb_sorted$phylum[i] != Under100_tb_sorted$phylum[i-1]){
    Under100_tb_sorted$selection_priority_2[i] <- 1
  } else {
    Under100_tb_sorted$selection_priority_2[i] <- Under100_tb_sorted$selection_priority_2[i-1] + 1
  }
}

Under100_tb_sorted$stays <- 1

for (j in 1:nrow(Under100_tb_sorted)) {
  current_phyllum <- Under100_tb_sorted$phylum[j]
  current_threshold <- Under100_tb_decisions$remaining[grep(current_phyllum, Under100_tb_decisions$phylum)]
  current_selection_priority <- Under100_tb_sorted$selection_priority_2[j]
  if(current_selection_priority > current_threshold){Under100_tb_sorted$stays[j] <- 0}
}



```


###Over100

```{r Over100_reduction}

Over100_tb_decisions <- Over100_tb %>% group_by(phylum) %>% summarise(phylum_count = n(), remaining = ceiling(0.75 * n()))
Over100_tb_decisions

Over100_tb$lottery <- sample(1:nrow(Over100_tb))

Over100_tb_sorted <- Over100_tb %>% arrange(phylum,
                                              lottery)

Over100_tb_sorted$selection_priority_2 <- 1

for (i in 2:nrow(Over100_tb_sorted)) {
  if(Over100_tb_sorted$phylum[i] != Over100_tb_sorted$phylum[i-1]){
    Over100_tb_sorted$selection_priority_2[i] <- 1
  } else {
    Over100_tb_sorted$selection_priority_2[i] <- Over100_tb_sorted$selection_priority_2[i-1] + 1
  }
}

Over100_tb_sorted$stays <- 1

for (j in 1:nrow(Over100_tb_sorted)) {
  current_phyllum <- Over100_tb_sorted$phylum[j]
  current_threshold <- Over100_tb_decisions$remaining[grep(current_phyllum, Over100_tb_decisions$phylum)]
  current_selection_priority <- Over100_tb_sorted$selection_priority_2[j]
  if(current_selection_priority > current_threshold){Over100_tb_sorted$stays[j] <- 0}
}



```


###Over500

```{r Over100_reduction}

Over500_tb_decisions <- Over500_tb %>% group_by(phylum) %>% summarise(phylum_count = n(), remaining = ceiling(0.7 * n()))
Over500_tb_decisions

Over500_tb$lottery <- sample(1:nrow(Over500_tb))

Over500_tb_sorted <- Over500_tb %>% arrange(phylum,
                                              lottery)

Over500_tb_sorted$selection_priority_2 <- 1

for (i in 2:nrow(Over500_tb_sorted)) {
  if(Over500_tb_sorted$phylum[i] != Over500_tb_sorted$phylum[i-1]){
    Over500_tb_sorted$selection_priority_2[i] <- 1
  } else {
    Over500_tb_sorted$selection_priority_2[i] <- Over500_tb_sorted$selection_priority_2[i-1] + 1
  }
}

Over500_tb_sorted$stays <- 1

for (j in 1:nrow(Over500_tb_sorted)) {
  current_phyllum <- Over500_tb_sorted$phylum[j]
  current_threshold <- Over500_tb_decisions$remaining[grep(current_phyllum, Over500_tb_decisions$phylum)]
  current_selection_priority <- Over500_tb_sorted$selection_priority_2[j]
  if(current_selection_priority > current_threshold){Over500_tb_sorted$stays[j] <- 0}
}




```

#### Ahora cortaremos cada una de las tablas para dejar sólo los genomas que nos interesan de cada phylum.


```{r Phylum_reduction}

# Primero combinamos todas las tablas
Phylum_decisions <- rbind(Under100_tb_sorted,Over100_tb_sorted,Over500_tb_sorted)

# Luego eliminamos todas aquellas filas con valor de 0 en la columna "stays"

Phylum_reduced <- Phylum_decisions[grepl(1,Phylum_decisions$stays),]
Phylum_reduced

```

### Criterio 4: Reducción específica en linajes sobre representados. Estableceremos tomar un genoma por género.

```{r Family_reduction}

Phylum_reduced_fulltax <- Phylum_reduced %>% unite("Full_taxonomy", phylum:genus, na.rm = TRUE, remove = FALSE)

Phylum_reduced_fulltax$`Assembly Level` <- as.factor(Phylum_reduced_fulltax$`Assembly Level`)
Phylum_reduced_fulltax$`Assembly Level` <- factor(Phylum_reduced_fulltax$`Assembly Level`,  levels = c("Complete Genome", "Chromosome", "Scaffold"))
Phylum_reduced_fulltax$Assembly_score <- unclass(Phylum_reduced_fulltax$`Assembly Level`)

Phylum_reduced_fulltax_sorted <- Phylum_reduced_fulltax %>% arrange(Full_taxonomy,
                           Assembly_score,
                           desc(pcount),
                           desc(`Assembly Submission Date`))

Phylum_reduced_fulltax_sorted$selection_priority <- 1

for (i in 2:nrow(Phylum_reduced_fulltax_sorted)) {
  if(Phylum_reduced_fulltax_sorted$Full_taxonomy[i] != Phylum_reduced_fulltax_sorted$Full_taxonomy[i-1]){
    Phylum_reduced_fulltax_sorted$selection_priority[i] <- 1
  } else {
    Phylum_reduced_fulltax_sorted$selection_priority[i] <- Phylum_reduced_fulltax_sorted$selection_priority[i-1] + 1
  }
}

max_count <- 3

reduced_by_genus <- Phylum_reduced_fulltax_sorted[(!Phylum_reduced_fulltax_sorted$selection_priority > max_count),]
reduced_by_genus

```

```{r save_genome_list}

sink("reduced_genome_list.txt")
for (i in 1:nrow(reduced_by_genus)) {
  id <- reduced_by_genus$`Assembly Accession...2`[i]
  cat(gsub("\\..*","",id))
  cat("\t")
  cat(gsub(" ","_",reduced_by_genus$species[i]))
  cat("\n")
}
sink()

readr::write_csv(reduced_by_genus, "reduced_genomes_metadata.csv")

```

Ahora que tenemos una lista sólo con los genomas que nos interesan para el estudio 
podremos descargarlos para utilizar el programa "get_homologues"


### 4) Get_ homologues

Parameter |   Value   |     Description
-t        |    0      | Report sequence clusters including at least t taxa. (t=0 reports all clusters [OMCL|COGS]).
-M        |           | Use orthoMCL algorithm (OMCL, PubMed=12952885)
-C        |    75     | min %coverage in BLAST pairwise alignments (range [1-100])
-E        |   1e-05   | max E-value
-r        |           | reference proteome .faa/.gbk file
-n        |    10     | nb of threads for BLAST/HMMER/MCL in 'local' runmode



```
```


### 5) Matriz presencia- ausencia

``` {r filter_matrix}

homologues_dir_path <- "/home/arquea/Pangenómica/Arqueas_2023/gbk_files_homologues/"
cluster_list_file_path <- list.files(path = homologues_dir_path, pattern=".cluster_list", full.names = TRUE)
cluster_list_file <- read_lines(cluster_list_file_path)

test_cluster <- grepl("cluster ", cluster_list_file)
clusterverse <- cluster_list_file[test_cluster] %>% gsub("cluster ","",.) %>% gsub(" .*","",.) %>% unique()
genomeverse <- cluster_list_file[!test_cluster] %>% gsub(": _","",.) %>% unique()

pan_matrix <- matrix(nrow = length(clusterverse), ncol = length(genomeverse))
colnames(pan_matrix) <- genomeverse
rownames(pan_matrix) <- clusterverse
pan_matrix[] <- 0L            

index_cluster = 0

for (e in cluster_list_file) {
  if(grepl("cluster ", e)){
    index_cluster = index_cluster + 1
    cur_clust <- e %>% gsub("cluster ","",.) %>% gsub(" .*","",.)
  }else{
    cur_genome <- e %>% gsub(": _","",.)
    index_genome <- grep(cur_genome,genomeverse)
    pan_matrix[index_cluster,index_genome] <- 1
  }
}

write.csv(pan_matrix, file = "les_nutries.csv")
  
``` 




# FILTRAR MATRIZ (NO SINGLETONES)

``` {r filter_matrix}
#### FILTRAR MATRIZ (NO SINGLETONES)
unfiltered_binary_pangenome_matrix <- as.data.frame.array(pan_matrix)

binary_pangenome_matrix_plus_sum <- unfiltered_binary_pangenome_matrix %>%
  replace(is.na(.), 0) %>%
  mutate(sum= rowSums(.))

plot(hist(binary_pangenome_matrix_plus_sum$sum))

#Filtrar singletones

porcentaje=5


ngenomas= ncol(binary_pangenome_matrix_plus_sum)-1
num_gen_perc = (ngenomas*(porcentaje))/100

binary_pm_No_singletones<- binary_pangenome_matrix_plus_sum %>% 
  filter(sum > num_gen_perc)

binary_pm_No_singletones_No_Hypothetical <- binary_pm_No_singletones %>% 
  filter(!grepl("hypothetical", rownames(binary_pm_No_singletones)))

plot(hist(binary_pm_No_singletones$sum))


table(as.character(binary_pangenome_matrix_plus_sum$sum)) %>% sort()

binary_pangenome_matrix <- binary_pm_No_singletones_No_Hypothetical[,!(colnames(binary_pm_No_singletones_No_Hypothetical)=="sum")]
write_csv(binary_pangenome_matrix, "/home/arquea/Downloads/revbayes-v1.2.1-linux64/revbayes-v1.2.1/data/matriz_pangenomica_nutries_no_singletones_no_hypothetical.csv")
```

### 6) Construcción de filogenia

```{r phylogeny}

#Estimación de matriz de distancias

Distance_matrix <- stats::dist(t(binary_pangenome_matrix))

Distance_matrix.tb <- as.data.frame(as.matrix(Distance_matrix)) 
colnames(Distance_matrix.tb) <- colnames(binary_pangenome_matrix)
rownames(Distance_matrix.tb) <- colnames(binary_pangenome_matrix)

Distance_matrix.tb <- Distance_matrix.tb[-1, -1]   #Este sólo si se añade una columna y una fila sin valores

Distance_matrix.tb <- Distance_matrix.tb[-grep("tmp", rownames(Distance_matrix.tb)), -grep("tmp", rownames(Distance_matrix.tb))]  #y este


NJ <- ape::njs(as.dist(Distance_matrix.tb))


#Añadir valores de bootstrap


library(ape)
f <- function(njs) njs(as.dist(Distance_matrix.tb))
boot_values <- boot.phylo(NJ, Distance_matrix.tb, f, B = 300, block = 1)
boot_values


######Probar con #####


library(phangorn)

f <- function(njs) njs(as.dist(Distance_matrix.tb))

NJtrees <- bootstrap.pml(Distance_matrix.tb, f, bs = 100)

treeBS <- plotBS( NJ, NJtrees, "phylogram") 

NJ$node.label <- boot_values
######################
ape::write.tree(NJ, "Filogenia_Abe&Hilda.txt")

```


```{r Filogenia_bayesiana}
library(phangorn)

library(phytools)
library(ape)

library(MCMCtreeR)

phy_dat <- phyDat(binary_pangenome_matrix, type = "USER", levels = c("0", "1"))


parsimony(phy_dat)


dist_jaccard <- dist(as.matrix(binary_pangenome_matrix), method = "binary")
nj_tree <- nj(dist_jaccard)

n_edges <- nrow(nj_tree$edge) + 1
edge <- matrix(0, nrow = 2, ncol = (2 * n_edges))
edge[1, ] <- 1:n_edges
edge[2, 1] <- seq(n_edges, length.out = n_edges)
edge[2, 2] <- nj_tree$edge[, 2] + n_edges
edge[2, 3:n_edges] <- nj_tree$edge[, 1] + n_edges

# Crear objeto pbtree
pbtree_obj <- pbtree(phy_dat, edge = edge, method = "mcmc")

pbtree_obj <- pbtree(phy_dat, tree = nj_tree, method = "mcmc")



```


``` {r filter_matrix}
#### FILTRAR MATRIZ (NO SINGLETONES)
unfiltered_binary_pangenome_matrix <- as.data.frame.array(pan_matrix)

binary_pangenome_matrix_plus_sum <- unfiltered_binary_pangenome_matrix[,-1] %>%
  replace(is.na(.), 0) %>%
  mutate(sum= rowSums(.))

plot(hist(binary_pangenome_matrix_plus_sum$sum))

#Filtrar singletones

porcentaje=5
```



```{r jo}
# Cargar la matriz de caracteres binarios
matriz_caracteres <- binary_pangenome_matrix

# Calcular la matriz de distancia de Jaccard
dist_jaccard <- as.dist(dist(as.matrix(matriz_caracteres), method = "binary"))

# Generar un árbol de Neighbor-Joining
d <- attr(dist_jaccard, "Size")
X <- 1:d
Y <- rep(0, d)
splits <- vector(mode = "list", length = d - 1)
for (k in 2:d) {
    Xk <- X[1:(d - k + 1)]
    Y[k] <- sum(dist_jaccard[Xk, k]) / (d - 2)
    splits[[k - 1]] <- cbind(Xk, rep(k, length(Xk)))
    X <- c(X, k)
}
nj_tree <- list(edge = cbind(0, Y), tip.label = 1:d, edge.length = rep(0, d - 1), Nnode = d - 1, node.label = NULL)

# Crear objeto phyDat
phy_dat <- list(type = "USER", character = as.character(t(matriz_caracteres)))

# Crear objeto edge
n_edges <- nj_tree$Nnode + nj_tree$Ntip
edge <- matrix(0, nrow = 2, ncol = (2 * n_edges))
edge[1, ] <- 1:n_edges
edge[2, 1] <- seq(nj_tree$Ntip + 1, length.out = nj_tree$Nnode) + nj_tree$Ntip
edge[2, 2] <- nj_tree$edge[, 2] + nj_tree$Ntip
edge[2, 3:nj_tree$Nnode] <- nj_tree$edge[, 1] + nj_tree$Ntip

# Realizar el análisis de MCMC
set.seed(123)  # Fijar la semilla para reproducibilidad
n_gen <- 10000  # Número de generaciones
sample_freq <- 10  # Frecuencia de muestreo
n_samples <- n_gen / sample_freq  # Número de muestras
samples <- matrix(0, nrow = n_samples, ncol = nj_tree$Nnode + nj_tree$Ntip)
samples[1, ] <- rep(1, nj_tree$Nnode + nj_tree$Ntip)
for (i in 2:n_samples) {
    for (j in 1:sample_freq) {
        samples[(i - 1) * sample_freq + j, ] <- update_tree(nj_tree, samples[(i - 2) * sample_freq + j, ])
    }
}
```